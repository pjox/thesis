%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Quality at Glance Related Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}\label{sec:related}

Corpora collected by web crawlers are known to be noisy~\citep{junczys-dowmunt-2019-microsoft,luccioni-viviano-2021-whats}. In highly multilingual settings, past work found that web-crawls of lower-resource languages have serious issues, especially with segment-level LangID~\citep{caswell-etal-2020-language}.
%Repeated studies have shown that 
Cleaning and filtering web-crawls can boost general language modeling~\citep{gao-etal-2020-the,brown-etal-2020-language,raffel-etal-2020-exploring} and downstream task performance~\citep{moore-lewis-2010-intelligent,rarrick-etal-2011-mt,xu-koehn-2017-zipporah,khayrallah-koehn-2018-impact,brown-etal-2020-language}.

As the scale of ML research grows, it becomes increasingly difficult to validate automatically collected and curated datasets \citep{biderman-etal-2020-pitfalls,birhane-etal-2021-large,bender-etal-2021-on}.
%Data Quality Considerations for Big Data and Machine Learning: Going Beyond Data Cleaning and Transformations \citep{gudivada2017data}
Several works have focused on advancing methodologies and best practices to address these challenges. \citet{bender-friedman-2018-data} introduced data statements, a documentary framework for NLP datasets that seeks to provide a universal minimum bar for dataset description. Similar work has been done on systematizing documentation in other areas in data science and machine learning, including work focusing on
online news \citep{kevin-etal-2018-information}, data ethics \citep{sun-etal-2019-mithralabel}, and data exploration \citep{holland-etal-2018-the}, as well as generalist work such as \citep{gebru-etal-2018-datasheets}. 
Data quality is also implicitly documented by successes of filtering methods. There is a large literature on filtering data for various NLP tasks, e.g. \citet{axelrod-etal-2011-domain,moore-lewis-2010-intelligent,rarrick-etal-2011-mt,wang-etal-2018-denoising,kamholz-etal-2014-panlex,junczys-dowmunt-2018-dual,caswell-etal-2020-language}.

Closest to our work is the analysis of a highly multilingual (non-publicly available) web-crawl and LangID related quality issues by \citet{caswell-etal-2020-language}.
%, performing a highly multilingual web-crawl and then systematically analyzing the LangID related quality issues. 
%However, though 
They perform a brief analysis of the quality of OSCAR
%, but omit analyses of any other public datasets, 
with the focus only on the presence of in-language content.
\citet{dodge-etal-2021-documenting} automatically documented and analyzed the contents and sources of C4~\citep{raffel-etal-2020-exploring}, the English counterpart of mC4, which surfaced the presence of machine-translated contents and NLP benchmark data.

\section{Multilingual Corpora}\label{sec:crawls}

\begin{table*}[th!]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{lccccc}
            \toprule
                            & \multicolumn{3}{c}{\textbf{Parallel}} & \multicolumn{2}{c}{\textbf{Monolingual}}                                                       \\
            \cmidrule(lr){2-4} \cmidrule(lr){5-6}
                            & \textbf{CCAligned}                    & \textbf{ParaCrawl v7.1}                  & \textbf{WikiMatrix} & \textbf{OSCAR} & \textbf{mC4} \\
            \midrule
            \#languages     & 137                                   & 41                                       & 85                  & 166            & 101          \\
            Source          & CC 2013--2020                         & selected websites                        & Wikipedia           & CC 11/2018     & CC all       \\
            Filtering level & document                              & sentence                                 & sentence            & document       & document     \\
            Langid          & FastText                              & CLD2                                     & FastText            & FastText       & CLD3         \\
            Alignment       & LASER                                 & Vec/Hun/BLEU-Align                       & LASER               & -              & -            \\
            Evaluation      & TED-6                                 & WMT-5                                    & TED-45              & POS/DEP-5      & XTREME       \\
            \bottomrule
        \end{tabular}%
    }
    \caption{Comparison of parallel and monolingual corpora extracted from web documents, including their downstream evaluation tasks. All parallel corpora are evaluated for machine translation (BLEU). TED-6: \texttt{da}, \texttt{cr}, \texttt{sl}, \texttt{sk}, \texttt{lt}, \texttt{et}; TED-45: 45-language subset of ~\citep{qi-etal-2018-pre}; WMT-5: \texttt{cs}, \texttt{de}, \texttt{fi}, \texttt{lv}, \texttt{ro}. POS/DEP-5: part-of-speech labeling and dependency parsing for \texttt{bg}, \texttt{ca}, \texttt{da}, \texttt{fi}, \texttt{id}.}
    \label{tab:corpora}
\end{table*}
% CC: CommonCrawl; TED-6: da, cr, sl, sk, lt, et; TED-50: TODO cite Qi et al. 2018; WMT-5: cs, de, fi, lv, ro.
%fastText: 176 languages, Wikipedia & Tatoeba


Table \ref{tab:corpora} provides an overview of the corpora of interest in this work. We selected the corpora for their multilinguality and the inclusion of understudied languages in NLP. With the exception of WikiMatrix and ParaCrawl, all corpora are derived from CommonCrawl (CC).\footnote{\url{http://commoncrawl.org/}} %s, and distinguish themselves by the choice of filtering methods, LangID and automatic alignment technology.
%LangID is crucial to corpus creation, since any issues within might propagate, e.g. bias recognizing document types similar to what it was trained on, or errors in language identifiers.\footnote{\url{https://github.com/facebookresearch/fastText/issues/482}}


\paragraph{CCAligned~\citep{el-kishky-etal-2020-ccaligned}}is a %119-language\footnote{119 of originally 137 available for download (02/2021)}
%Although 137 language pairs are reported in ~\citet{el-kishky-etal-2020-ccaligned}, only 119 sentence-level corpora were available to download on \url{statmt.org} as of February 2021.}
parallel dataset built off 68 CC snapshots. Documents are aligned if they are in the same language according to FastText LangID~\citep{joulin-etal-2016-fasttext,joulin-etal-2017-bag}, and have the same URL but for a differing language code. These alignments are refined with cross-lingual LASER embeddings \citep{artetxe-schwenk-2019-massively}. For sentence-level data, they split on newlines and align with LASER, but perform no further filtering.
Human annotators evaluated the quality of document alignments for six languages (\texttt{de}, \texttt{zh}, \texttt{ar}, \texttt{ro}, \texttt{et}, \texttt{my}) selected for their different scripts and amount of retrieved documents, reporting precision of over 90\%.
% Latin, Chinese, Arabic, Burmese script
The quality of the extracted parallel sentences was evaluated in a machine translation (MT) task on six European (\texttt{da}, \texttt{cr}, \texttt{sl}, \texttt{sk}, \texttt{lt}, \texttt{et}) languages of the TED corpus~\citep{qi-etal-2018-pre}, where it compared favorably to systems built on crawled sentences from WikiMatrix and ParaCrawl v6. %, yielding BLEU scores in a range between 15 and 38.  

\paragraph{Multilingual C4 (mC4)~\citep{xue-etal-2021-mt5}} is a document-level dataset used for training the mT5 language model. It consists of monolingual text in 101 languages and is generated from 71 CC snapshots. It filters out pages that contain less than three lines of at least 200 characters and pages that contain bad words.\footnote{\url{https://github.com/LDNOOBW/}} Since this is a document-level dataset, we split it by sentence and deduplicate it before rating. For language identification, it uses CLD3~\citep{botha-etal-2017-natural},\footnote{\url{https://github.com/google/cld3/}} a small feed-forward neural network that was trained to detect 107 languages.
The mT5 model pre-trained on mC4
is evaluated on 6 tasks of the XTREME benchmark~\citep{hu-etal-2020-xtreme} covering a variety of languages and outperforms other multilingual pre-trained language models such as mBERT~\citep{devlin-etal-2019-bert} and XLM\nobreakdash-R~\citep{conneau-etal-2020-unsupervised}.%\footnote{mBERT is trained on Wikipedia, {XML\nobreakdash-R} on CommonCrawl.} 

\paragraph{OSCAR~\citep{ortiz-suarez-etal-2019-asynchronous, ortiz-suarez-etal-2020-monolingual}}is a set of monolingual corpora extracted from CC snapshots, specifically from the plain text \emph{WET} format distributed by CC which removes all the HTML tags and converts the text to UTF-8. It is deduplicated and follows the approach by~\citep{grave-etal-2018-learning} of using FastText LangID~\citep{joulin-etal-2016-fasttext, joulin-etal-2017-bag} on a line-level.\footnote{\url{https://fasttext.cc/docs/en/language-identification.html} } No other filtering was applied.
% 
For five languages (\texttt{bg}, \texttt{ca}, \texttt{da}, \texttt{fi}, \texttt{id}) OSCAR was used by its original authors to train language models which were then evaluated on parsing and POS tagging \citep{ortiz-suarez-etal-2020-monolingual}. OSCAR has also been used in independent studies to train monolingual or multilingual language models (\texttt{ar}, \texttt{as}, \texttt{bn}, \texttt{de}, \texttt{el}, \texttt{fr}, \texttt{gu}, \texttt{he}, \texttt{hi}, \texttt{kn}, \texttt{ml}, \texttt{mr}, \texttt{nl}, \texttt{or}, \texttt{pa}, \texttt{ro}, \texttt{ta}, \texttt{te}) and subsequently evaluate them on various downstream tasks \citep{antoun-etal-2021-araelectra, kakwani-etal-2020-indicnlpsuite, wilie-etal-2020-indonlu, chan-etal-2020-germans, koutsikakis-etal-2020-greek, martin-etal-2020-camembert, chriqui-etal-2021-hebert, seker-etal-2021-alephbert, delobelle-etal-2020-robbert, dumitrescu-etal-2020-birth, masala-etal-2020-robert}.


\paragraph{ParaCrawl v7.1} is a parallel dataset with 41 language pairs primarily aligned with English (39 out of 41) and mined using the parallel-data-crawling tool Bitextor \citep{espla-etal-2019-paracrawl,banon-etal-2020-paracrawl} which includes downloading documents, preprocessing and normalization, aligning documents and segments, and filtering noisy data via Bicleaner.\footnote{\url{https://github.com/bitextor/bicleaner}}
ParaCrawl focuses on European languages, but also includes 9 lower-resource, non-European language pairs in v7.1.
% TODO: https://www.aclweb.org/anthology/2020.eamt-1.31.pdf \citep{ramirez-sanchez-etal-2020-bifixer}
Sentence alignment and sentence pair filtering choices were optimized for five languages (\texttt{mt}, \texttt{et}, \texttt{hu}, \texttt{cs}, \texttt{de}) by training and evaluating MT models on the resulting parallel sentences. An earlier version (v5) was shown to improve translation quality on WMT benchmarks for~\texttt{cs}, \texttt{de}, \texttt{fi}, \texttt{lv}, \texttt{ro}.


\paragraph{WikiMatrix~\citep{schwenk-etal-2021-wikimatrix}} is a public dataset containing 135M parallel sentences in 1620 language pairs (85 languages) mined from Wikipedia. Out of the 135M parallel sentences, 34M are aligned with English. %, which we focus on.
%which relies on first learning multilingual sentence embeddings, and then applying the cosine distance metric to determine whether two sentences are close enough to be considered translations of each other.
The text is extracted from Wikipedia pages, split into sentences, and duplicate sentences are removed. FastText LangID is used before identifying bitext with LASER's distance-based mining approach.
The margin threshold is optimized by training and evaluating downstream MT models on four WMT benchmarks (\texttt{de-en}, \texttt{de-fr}, \texttt{cs-de}, \texttt{cs-fr}). The final dataset is used to train translation models that are then evaluated by automatically measuring the quality of their translations against human translations of TED talks in 45 languages, with highest quality for translations between English and e.g. \texttt{pt}, \texttt{es}, \texttt{da}, and lowest for \texttt{sr}, \texttt{ja}, \texttt{mr}, \texttt{zh\_TW}.
In the audit we focus on language pairs with English on one side.
% https://github.com/facebookresearch/LASER/blob/master/tasks/WikiMatrix/WikiMatrix-bleu.pdf
